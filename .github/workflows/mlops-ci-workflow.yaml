name: MLOps CI/CD Pipeline

on:

  workflow_dispatch:
    inputs:
      run_all:
        description: 'Run all jobs'
        required: false
        default: 'true'
      run_data_processing:
        description: 'Run data processing job'
        required: false
        default: 'false'
      run_model_training:
        description: 'Run model training job'
        required: false
        default: 'false'
      run_build_and_publish:
        description: 'Run build and publish job'
        required: false
        default: 'false'
  release:
    types: [ created ]
    branches: [ main ]
    tags: [ 'v*.*.*' ]

jobs:
  data-processing:
    runs-on: ubuntu-latest
    if: github.event_name != 'workflow_dispatch' || github.event.inputs.run_all == 'true' || github.event.inputs.run_data_processing == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11.11

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Data Preprocessing Tests
        run: |
          python src/data/run_processing.py \
          --input data/raw/data.csv \
          --output data/processed/cleaned_house_data_v1.csv

      - name: Run Feature Engineering Tests
        run: |
          python src/features/engineer.py \
          --input data/processed/final_data.csv \
          --output data/processed/featured_house_data.csv \
          --preprocessor models/trained/preprocessor.pkl

      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed/featured_house_data.csv

      - name: Upload preprocessor
        uses: actions/upload-artifact@v4
        with:
          name: preprocessor
          path: models/trained/preprocessor.pkl

  model-training:
    needs: data-processing
    runs-on: ubuntu-latest
    if: github.event_name != 'workflow_dispatch' || github.event.inputs.run_all == 'true' || github.event.inputs.run_model_training == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11.11

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed/

      - name: Set up MLflow
        run: |
          docker pull ghcr.io/mlflow/mlflow:latest
          docker run -d -p 5000:5000 --name mlflow-server ghcr.io/mlflow/mlflow:latest mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow.db

      - name: Wait for MLflow to start
        run: |
          for i in {1..10}; do
            if curl -f http://localhost:5000/health 2>/dev/null; then
              echo "MLflow server is ready!"
              exit 0
            fi
            echo "Waiting for MLflow server... attempt $i/30"
            sleep 2
          done
          echo "MLflow server failed to start"
          exit 1

      - name: Create models directory
        run: mkdir -p models

      - name: Train model
        run: |
          python src/models/train_model.py \
          --config configs/model_config.yaml \
          --data data/processed/featured_house_data.csv \
          --models-dir models \
          --mlflow-tracking-uri http://localhost:5000

      - name: Upload trained model
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: models/

      - name: Cleaning up MLFlow
        if: always()
        run: |
          docker stop mlflow-server || true
          docker rm mlflow-server || true
          docker rmi ghcr.io/mlflow/mlflow:latest || true

  build-and-publish:
    needs: model-training
    runs-on: ubuntu-latest
    if: github.event_name != 'workflow_dispatch' || github.event.inputs.run_all == 'true' || github.event.inputs.run_build_and_publish == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Download trained model
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: models/

      - name: Download preprocessor
        uses: actions/download-artifact@v4
        with:
          name: preprocessor
          path: models/trained/

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and test Docker image
        run: |
          COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
          docker build -t docker.io/${{ vars.DOCKERHUB_USERNAME }}/fastapi:$COMMIT_HASH -f Dockerfile .
          docker run -d -p 8000:8000 --name test-api docker.io/${{ vars.DOCKERHUB_USERNAME }}/fastapi:$COMMIT_HASH
          for i in {1..10}; do
            if curl -f http://localhost:8000/health 2>/dev/null; then
              echo "API is ready!"
              break
            fi
            echo "Waiting for API... attempt $i/10"
            sleep 5
          done
          docker logs test-api

      - name: Clean up Test Container
        if: always()
        run: |
          docker stop test-api || true
          docker rm test-api || true

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: docker.io
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Push Docker image to DockerHub
        run: |
          COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
          docker tag docker.io/${{ vars.DOCKERHUB_USERNAME }}/fastapi:$COMMIT_HASH docker.io/${{ vars.DOCKERHUB_USERNAME }}/fastapi:latest
          docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/fastapi:$COMMIT_HASH
          docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/fastapi:latest